{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted and saved 67 mouth frames from C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\Varutham.mp4.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "\n",
    "shape_predictor_path = r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\shape_predictor_68_face_landmarks (1).dat'\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(shape_predictor_path)\n",
    "\n",
    "def extract_mouth_from_frame(frame, predictor, detector, frame_size=(220, 220)):\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect faces\n",
    "    faces = detector(gray)\n",
    "    if len(faces) > 0:\n",
    "        # Get the first face detected\n",
    "        face = faces[0]\n",
    "        # Get the landmarks for the face\n",
    "        landmarks = predictor(gray, face)\n",
    "        # Get the coordinates for the mouth region\n",
    "        mouth_coords = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(48, 68)]\n",
    "        # Get the bounding box for the mouth region\n",
    "        x_min = min(mouth_coords, key=lambda x: x[0])[0]\n",
    "        x_max = max(mouth_coords, key=lambda x: x[0])[0]\n",
    "        y_min = min(mouth_coords, key=lambda x: x[1])[1]\n",
    "        y_max = max(mouth_coords, key=lambda x: x[1])[1]\n",
    "        # Extract the mouth region\n",
    "        mouth_region = frame[y_min:y_max, x_min:x_max]\n",
    "        # Resize the mouth region\n",
    "        resized_mouth = cv2.resize(mouth_region, frame_size)\n",
    "        return resized_mouth\n",
    "    return None\n",
    "\n",
    "def extract_frames_from_video(video_path, output_folder, frame_size=(220, 220)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        mouth_frame = extract_mouth_from_frame(frame, predictor, detector, frame_size)\n",
    "        if mouth_frame is not None:\n",
    "            frame_path = os.path.join(output_folder, f\"frame_{count:04d}.jpg\")\n",
    "            cv2.imwrite(frame_path, mouth_frame)\n",
    "            count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"Extracted and saved {count} mouth frames from {video_path}.\")\n",
    "\n",
    "# Example usage\n",
    "video_path = r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\Varutham.mp4'  \n",
    "output_folder = r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\Varutham Frames'  \n",
    "extract_frames_from_video(video_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, TimeDistributed, Dense, Bidirectional, LSTM, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_video_frames(video_folder, frame_size=(220, 220)):\n",
    "    video_frames = []\n",
    "    frame_files = sorted(os.listdir(video_folder))\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(video_folder, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        if frame is None:\n",
    "            continue\n",
    "        resized_frame = cv2.resize(frame, frame_size)\n",
    "        normalized_frame = resized_frame / 255.0\n",
    "        video_frames.append(normalized_frame)\n",
    "    return np.array(video_frames)\n",
    "\n",
    "def preprocess_data(data_dir, frame_size=(220, 220)):\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = sorted(os.listdir(data_dir))\n",
    "    label_map = {label: idx for idx, label in enumerate(labels)}\n",
    "    for label in labels:\n",
    "        label_dir = os.path.join(data_dir, label)\n",
    "        if not os.path.isdir(label_dir):\n",
    "            continue\n",
    "        video_dirs = sorted(os.listdir(label_dir))\n",
    "        for video_dir in video_dirs:\n",
    "            video_path = os.path.join(label_dir, video_dir)\n",
    "            if not os.path.isdir(video_path):\n",
    "                continue\n",
    "            video_frames = load_video_frames(video_path, frame_size)\n",
    "            if video_frames.size > 0:\n",
    "                X.append(video_frames)\n",
    "                y.append(label_map[label])\n",
    "    return np.array(X), np.array(y), label_map\n",
    "\n",
    "# Example usage\n",
    "data_dir = r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING'\n",
    "X, y, label_map = preprocess_data(data_dir)\n",
    "num_classes = len(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Spatio-Temporal CNN\n",
    "    x = Conv3D(32, kernel_size=(3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), padding='same')(x)\n",
    "    x = Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), padding='same')(x)\n",
    "    x = Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), padding='same')(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    \n",
    "    # Bi-Directional LSTMs\n",
    "    x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "    x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "    x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "    \n",
    "    # Dense Layer\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(num_classes + 1, activation='softmax')(x)  # +1 for CTC blank\n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(label_map)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Define model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(input_shape, num_classes)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Compile model\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "data_dir = r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\Varutham Frames'\n",
    "X, y, label_map = preprocess_data(data_dir)\n",
    "num_classes = len(label_map)\n",
    "\n",
    "# Define model\n",
    "input_shape = (X.shape[1], X.shape[2], X.shape[3], X.shape[4])\n",
    "model = build_model(input_shape, num_classes)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(), loss={'ctc': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# Prepare training data\n",
    "y_input = np.zeros_like(y)\n",
    "input_length = np.full((len(y), 1), X.shape[1], dtype=int)\n",
    "label_length = np.array([[len(str(lbl))] for lbl in y], dtype=int)\n",
    "\n",
    "# Train model\n",
    "model.fit([X, y_input, input_length, label_length], y_input, epochs=100, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93312</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,944,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93312\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m11,944,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,037,570</span> (45.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,037,570\u001b[0m (45.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,037,570</span> (45.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,037,570\u001b[0m (45.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 181ms/step - accuracy: 0.9485 - loss: 0.0370\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m 27/100\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 177ms/step - accuracy: 1.0000 - loss: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Train the model with the generator\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust steps_per_epoch as needed\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Parameters\n",
    "batch_size = 1\n",
    "frame_size = (220, 220)  # Frame dimensions (height, width)\n",
    "num_classes = 2  # Adjust based on your label map, e.g., binary classification\n",
    "\n",
    "def frame_generator(data_dir, batch_size=1, frame_size=(220, 220)):\n",
    "    frame_folder = os.path.join(data_dir, 'Varutham Frames')\n",
    "    frame_files = sorted(os.listdir(frame_folder))\n",
    "    \n",
    "    while True:\n",
    "        frames = []\n",
    "        labels = []\n",
    "        for frame_file in frame_files:\n",
    "            frame_path = os.path.join(frame_folder, frame_file)\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                continue\n",
    "            resized_frame = cv2.resize(frame, frame_size)\n",
    "            normalized_frame = resized_frame / 255.0\n",
    "            frames.append(normalized_frame)\n",
    "            labels.append(0)  # Replace with actual label if needed\n",
    "            \n",
    "            if len(frames) == batch_size:\n",
    "                yield np.array(frames), np.array(labels)\n",
    "                frames, labels = [], []\n",
    "        \n",
    "        if frames:\n",
    "            yield np.array(frames), np.array(labels)\n",
    "\n",
    "# Model definition\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')  # Use 'sigmoid' for binary classification\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Load data and create generator\n",
    "data_dir = r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING'\n",
    "input_shape = (frame_size[0], frame_size[1], 3)  # (height, width, channels)\n",
    "train_generator = frame_generator(data_dir, batch_size=batch_size, frame_size=frame_size)\n",
    "\n",
    "# Build and compile the model\n",
    "model = build_model(input_shape, num_classes)\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Use 'binary_crossentropy' for binary classification\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model with the generator\n",
    "try:\n",
    "    model.fit(train_generator, steps_per_epoch=100, epochs=10)  # Adjust steps_per_epoch as needed\n",
    "except ValueError as e:\n",
    "    print(f\"Error during training: {e}\")\n",
    "\n",
    "# Evaluate the model with the generator (if necessary)\n",
    "try:\n",
    "    loss, accuracy = model.evaluate(train_generator, steps=100)  # Adjust steps as needed\n",
    "    print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error during evaluation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('Varutham.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('Varutham.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(test_folder, frame_size=(220, 220)):\n",
    "    frame_files = sorted(os.listdir(test_folder))\n",
    "    frames = []\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(test_folder, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        if frame is None:\n",
    "            continue\n",
    "        resized_frame = cv2.resize(frame, frame_size)\n",
    "        normalized_frame = resized_frame / 255.0\n",
    "        frames.append(normalized_frame)\n",
    "    return np.array(frames)\n",
    "\n",
    "test_folder = r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\Varutham test frames'  # Update this path to your test data folder\n",
    "test_data = prepare_test_data(test_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during evaluation: None values not supported.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "try:\n",
    "    loss, accuracy = model.evaluate(test_data, batch_size=1)\n",
    "    print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error during evaluation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Frame 0: Prediction Probability: 1.0, Predicted Label: 1\n",
      "Frame 1: Prediction Probability: 1.0, Predicted Label: 1\n",
      "Frame 2: Prediction Probability: 1.0, Predicted Label: 1\n",
      "Frame 3: Prediction Probability: 1.0, Predicted Label: 1\n",
      "Frame 4: Prediction Probability: 1.0, Predicted Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(test_data, batch_size=1)\n",
    "\n",
    "# Convert predictions to binary labels (0 or 1)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Print predictions and corresponding labels\n",
    "for i, (prediction, label) in enumerate(zip(predictions, predicted_labels)):\n",
    "    print(f\"Frame {i}: Prediction Probability: {prediction[0]}, Predicted Label: {label[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "The video contains: Varutham\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('Varutham.h5')  # Update with the path to your model\n",
    "\n",
    "def preprocess_frame(frame, frame_size=(220, 220)):\n",
    "    \"\"\"Preprocess the frame for model prediction.\"\"\"\n",
    "    resized_frame = cv2.resize(frame, frame_size)\n",
    "    normalized_frame = resized_frame / 255.0\n",
    "    return np.expand_dims(normalized_frame, axis=0)  # Add batch dimension\n",
    "\n",
    "def predict_video(video_path, model, frame_size=(220, 220)):\n",
    "    \"\"\"Predict the label for a video.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video file {video_path}\")\n",
    "    \n",
    "    frame_predictions = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        preprocessed_frame = preprocess_frame(frame, frame_size)\n",
    "        prediction = model.predict(preprocessed_frame)\n",
    "        \n",
    "        # Assuming binary classification with 0 and 1\n",
    "        predicted_label = (prediction > 0.5).astype(int)\n",
    "        frame_predictions.append(predicted_label[0][0])\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    return frame_predictions\n",
    "\n",
    "def analyze_video(predictions):\n",
    "    \"\"\"Analyze video predictions and determine if it contains the word 'Varutham'.\"\"\"\n",
    "    # Determine if 'Varutham' is present based on predictions\n",
    "    if np.any(np.array(predictions) == 1):\n",
    "        return \"Varutham\"\n",
    "    else:\n",
    "        return \"Not Varutham\"\n",
    "\n",
    "# Test with the video\n",
    "video_path = r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\Varutham (1).mp4'  # Update with the path to your video\n",
    "predictions = predict_video(video_path, model)\n",
    "result = analyze_video(predictions)\n",
    "\n",
    "print(f\"The video contains: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 67 mouth frames to Varutham Mouth Frames\n",
      "Extracted 51 mouth frames to Vanakkam Mouth Frames\n",
      "Extracted 42 mouth frames to Saapidu Mouth Frames\n",
      "Extracted 58 mouth frames to Sandhosham Mouth Frames\n",
      "Extracted 40 mouth frames to Nanri Mouth Frames\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def extract_mouth_region(frame, predictor, detector, frame_size=(220, 220)):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        # Mouth landmarks are from 48 to 67 in the 68-point model\n",
    "        mouth_points = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(48, 68)]\n",
    "        \n",
    "        # Convert the list of mouth points to a NumPy array\n",
    "        mouth_points = np.array(mouth_points)\n",
    "        \n",
    "        # Get bounding box for the mouth\n",
    "        x, y, w, h = cv2.boundingRect(mouth_points)\n",
    "        \n",
    "        # Extract the mouth region from the frame\n",
    "        mouth_region = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize to desired frame size\n",
    "        mouth_region = cv2.resize(mouth_region, frame_size)\n",
    "        \n",
    "        return mouth_region\n",
    "\n",
    "def extract_frames(video_path, output_folder, predictor, detector, frame_size=(220, 220)):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Extract the mouth region\n",
    "        mouth_region = extract_mouth_region(frame, predictor, detector, frame_size)\n",
    "        \n",
    "        if mouth_region is not None:\n",
    "            # Save frame as .jpg\n",
    "            frame_filename = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
    "            cv2.imwrite(frame_filename, mouth_region)\n",
    "            frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"Extracted {frame_count} mouth frames to {output_folder}\")\n",
    "\n",
    "# Load the pre-trained shape predictor model\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "# Example usage\n",
    "extract_frames('Varutham.mp4', 'Varutham Mouth Frames', predictor, detector)\n",
    "extract_frames('Vanakkam.mp4', 'Vanakkam Mouth Frames', predictor, detector)\n",
    "extract_frames('Saapidu.mp4', 'Saapidu Mouth Frames', predictor, detector)\n",
    "extract_frames('Sandhosham.mp4', 'Sandhosham Mouth Frames', predictor, detector)\n",
    "extract_frames('Nanri.mp4', 'Nanri Mouth Frames', predictor, detector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 208 images belonging to 5 classes.\n",
      "Found 50 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.2504 - loss: 3.3683 - val_accuracy: 0.2200 - val_loss: 1.6044\n",
      "Epoch 2/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.2947 - loss: 1.5761 - val_accuracy: 0.3600 - val_loss: 1.5976\n",
      "Epoch 3/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.3914 - loss: 1.4941 - val_accuracy: 0.3000 - val_loss: 1.5869\n",
      "Epoch 4/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.4939 - loss: 1.2891 - val_accuracy: 0.4400 - val_loss: 1.5426\n",
      "Epoch 5/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6131 - loss: 1.0517 - val_accuracy: 0.2800 - val_loss: 1.6096\n",
      "Epoch 6/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7305 - loss: 0.7258 - val_accuracy: 0.3400 - val_loss: 1.7708\n",
      "Epoch 7/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8630 - loss: 0.4184 - val_accuracy: 0.3200 - val_loss: 1.8398\n",
      "Epoch 8/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8775 - loss: 0.3583 - val_accuracy: 0.5400 - val_loss: 1.4627\n",
      "Epoch 9/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9246 - loss: 0.2449 - val_accuracy: 0.5000 - val_loss: 1.9628\n",
      "Epoch 10/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9426 - loss: 0.1811 - val_accuracy: 0.5800 - val_loss: 1.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Paths to the directories containing frames\n",
    "data_directory = r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\data'  # You should have a directory structure like 'data/Varutham', 'data/Vanakkam', etc.\n",
    "\n",
    "# Set up the ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=(220, 220),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=(220, 220),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(220, 220, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')  # Number of classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('video_classification_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "The video is classified as: Varutham Mouth Frames\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def preprocess_video(video_path, frame_size=(220, 220)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.resize(frame, frame_size)\n",
    "        frame = frame / 255.0\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "def predict_video_class(video_path, model_path='video_classification_model.h5'):\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    frames = preprocess_video(video_path)\n",
    "    if frames.shape[0] == 0:\n",
    "        return \"No frames extracted\"\n",
    "    \n",
    "    predictions = []\n",
    "    for frame in frames:\n",
    "        frame = np.expand_dims(frame, axis=0)  # Add batch dimension\n",
    "        pred = model.predict(frame)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    average_prediction = np.mean(predictions, axis=0)\n",
    "    predicted_class = np.argmax(average_prediction)\n",
    "    \n",
    "    class_labels = list(train_generator.class_indices.keys())\n",
    "    return class_labels[predicted_class]\n",
    "\n",
    "# Example usage\n",
    "video_class = predict_video_class(r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\Adhi Vanakkam test.mp4')\n",
    "print(f\"The video is classified as: {video_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 51 mouth frames to Vanakkam Mouth Frames\n",
      "Extracted 42 mouth frames to Saapidu Mouth Frames\n",
      "Extracted 58 mouth frames to Sandhosham Mouth Frames\n",
      "Extracted 40 mouth frames to Nanri Mouth Frames\n",
      "Found 154 images belonging to 4 classes.\n",
      "Found 37 images belonging to 4 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7927 - loss: 0.6082 - val_accuracy: 0.5946 - val_loss: 0.8521\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.8543 - loss: 0.3963 - val_accuracy: 0.5135 - val_loss: 1.0124\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.8672 - loss: 0.3840 - val_accuracy: 0.6216 - val_loss: 0.6071\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8608 - loss: 0.3137 - val_accuracy: 0.7297 - val_loss: 0.5447\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8842 - loss: 0.2298 - val_accuracy: 0.7297 - val_loss: 0.6386\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9065 - loss: 0.2296 - val_accuracy: 0.8108 - val_loss: 0.4972\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9649 - loss: 0.1161 - val_accuracy: 0.8108 - val_loss: 0.4431\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9796 - loss: 0.1266 - val_accuracy: 0.8108 - val_loss: 0.4292\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9413 - loss: 0.1066 - val_accuracy: 0.7838 - val_loss: 0.5722\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9479 - loss: 0.1276 - val_accuracy: 0.8919 - val_loss: 0.5281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "The video is classified as: Saapidu Mouth Frames\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def extract_mouth_region(frame, predictor, detector, frame_size=(220, 220)):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        mouth_points = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(48, 68)]\n",
    "        mouth_points = np.array(mouth_points)\n",
    "        x, y, w, h = cv2.boundingRect(mouth_points)\n",
    "        mouth_region = frame[y:y+h, x:x+w]\n",
    "        mouth_region = cv2.resize(mouth_region, frame_size)\n",
    "        return mouth_region\n",
    "    return None\n",
    "\n",
    "def extract_frames(video_path, output_folder, predictor, detector, frame_size=(220, 220)):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        mouth_region = extract_mouth_region(frame, predictor, detector, frame_size)\n",
    "        if mouth_region is not None:\n",
    "            frame_filename = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
    "            cv2.imwrite(frame_filename, mouth_region)\n",
    "            frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"Extracted {frame_count} mouth frames to {output_folder}\")\n",
    "\n",
    "# Load the pre-trained shape predictor model\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "# Example usage\n",
    "# extract_frames('Varutham.mp4', 'Varutham Mouth Frames', predictor, detector)\n",
    "extract_frames('Vanakkam.mp4', 'Vanakkam Mouth Frames', predictor, detector)\n",
    "extract_frames('Saapidu.mp4', 'Saapidu Mouth Frames', predictor, detector)\n",
    "extract_frames('Sandhosham.mp4', 'Sandhosham Mouth Frames', predictor, detector)\n",
    "extract_frames('Nanri.mp4', 'Nanri Mouth Frames', predictor, detector)\n",
    "\n",
    "# Prepare data\n",
    "def prepare_data(data_directory, image_size=(220, 220)):\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        data_directory,\n",
    "        target_size=image_size,\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "    \n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        data_directory,\n",
    "        target_size=image_size,\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator\n",
    "\n",
    "data_directory = 'data'  # Update this path if needed\n",
    "train_generator, validation_generator = prepare_data(data_directory)\n",
    "\n",
    "# Define the model\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'), input_shape=input_shape),\n",
    "        TimeDistributed(MaxPooling2D((2, 2))),\n",
    "        TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same')),\n",
    "        TimeDistributed(MaxPooling2D((2, 2))),\n",
    "        TimeDistributed(Conv2D(128, (3, 3), activation='relu', padding='same')),\n",
    "        TimeDistributed(MaxPooling2D((2, 2))),\n",
    "        TimeDistributed(Flatten()),\n",
    "        Bidirectional(LSTM(128, return_sequences=True)),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "\n",
    "# Save the model\n",
    "model.save('mouth_recognition_model.h5')\n",
    "\n",
    "# Load the model for testing\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('mouth_recognition_model.h5')\n",
    "\n",
    "def predict_video(video_path, model, predictor, detector, frame_size=(220, 220)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    predictions = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        mouth_region = extract_mouth_region(frame, predictor, detector, frame_size)\n",
    "        if mouth_region is not None:\n",
    "            mouth_region = np.expand_dims(mouth_region, axis=0) / 255.0\n",
    "            pred = model.predict(mouth_region)\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    avg_prediction = np.mean(predictions, axis=0)\n",
    "    class_label = np.argmax(avg_prediction)\n",
    "    \n",
    "    class_labels = {v: k for k, v in train_generator.class_indices.items()}\n",
    "    return class_labels[class_label]\n",
    "\n",
    "# Test the model\n",
    "video_path = r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\Adhi Vanakkam test.mp4'  # Update this path if needed\n",
    "predicted_class = predict_video(video_path, model, predictor, detector)\n",
    "print(f\"The video is classified as: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "The video is classified as: Nanri Mouth Frames\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "video_path = r'C:\\Users\\AdithiyanPV\\OneDrive\\Desktop\\LIP READING EXISTING\\Nikhil Vanakkam test.mp4'  # Update this path if needed\n",
    "predicted_class = predict_video(video_path, model, predictor, detector)\n",
    "print(f\"The video is classified as: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 308ms/step\n",
      "Confusion Matrix:\n",
      " [[1 0 1 1 5]\n",
      " [0 2 1 1 4]\n",
      " [1 2 1 4 3]\n",
      " [0 2 1 2 5]\n",
      " [0 1 4 2 6]]\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "     Nanri Mouth Frames       0.50      0.12      0.20         8\n",
      "   Saapidu Mouth Frames       0.29      0.25      0.27         8\n",
      "Sandhosham Mouth Frames       0.12      0.09      0.11        11\n",
      "  Vanakkam Mouth Frames       0.20      0.20      0.20        10\n",
      "  Varutham Mouth Frames       0.26      0.46      0.33        13\n",
      "\n",
      "               accuracy                           0.24        50\n",
      "              macro avg       0.27      0.23      0.22        50\n",
      "           weighted avg       0.26      0.24      0.22        50\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict on validation set\n",
    "val_labels = validation_generator.classes\n",
    "val_preds = model.predict(validation_generator)\n",
    "val_preds = np.argmax(val_preds, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(val_labels, val_preds)\n",
    "print('Confusion Matrix:\\n', conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report:\\n', classification_report(val_labels, val_preds, target_names=list(train_generator.class_indices.keys())))\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=list(train_generator.class_indices.keys()), yticklabels=list(train_generator.class_indices.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
